import streamlit as st
import requests
from io import BytesIO
from PIL import Image
from openai import OpenAI
import base64

# Configuration de la page
st.set_page_config(
    page_title="Analyse d'Images Vision",
    page_icon="ğŸ‘ï¸",
    layout="wide"
)

# Titre de la page
st.title("ğŸ‘ï¸ Analyse d'Images avec Vision AI")
st.markdown("---")

# Configuration de l'API OpenAI avec saisie utilisateur
def initialize_openai_client(api_key):
    """Initialise le client OpenAI avec la clÃ© API fournie par l'utilisateur"""
    try:
        if not api_key:
            return None
        
        if not api_key.startswith('sk-'):
            st.error("âŒ Format de clÃ© API invalide. La clÃ© doit commencer par 'sk-'")
            return None
        
        # Initialisation du client OpenAI
        client = OpenAI(api_key=api_key)
        
        # Test de validation de la clÃ© API
        try:
            # Test simple pour vÃ©rifier si la clÃ© fonctionne
            test_response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1
            )
            return client
        except Exception as e:
            st.error(f"âŒ ClÃ© API invalide ou problÃ¨me de connexion: {str(e)}")
            return None
            
    except Exception as e:
        st.error(f"âŒ Erreur lors de l'initialisation du client OpenAI: {str(e)}")
        return None

def vision_analyze_image(client, image, analysis_type="general"):
    """
    Analyse une image avec l'API Vision d'OpenAI
    
    Args:
        client: Client OpenAI initialisÃ©
        image: Image PIL Ã  analyser
        analysis_type: Type d'analyse ("general", "objects", "text", "detailed")
    
    Returns:
        str: Description/analyse de l'image
    """
    try:
        # Conversion de l'image en base64
        img_buffer = BytesIO()
        image.save(img_buffer, format='PNG')
        img_buffer.seek(0)
        image_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
        
        # DÃ©finir le prompt selon le type d'analyse
        prompts = {
            "general": "DÃ©cris cette image de maniÃ¨re dÃ©taillÃ©e. Que vois-tu ?",
            "objects": "Identifie et liste tous les objets visibles dans cette image. Sois prÃ©cis et mÃ©thodique.",
            "text": "Y a-t-il du texte dans cette image ? Si oui, transcris-le et explique son contexte.",
            "detailed": "Fais une analyse complÃ¨te et dÃ©taillÃ©e de cette image : objets, personnes, couleurs, composition, style, ambiance, texte Ã©ventuel, et tout autre Ã©lÃ©ment notable.",
            "artistic": "Analyse cette image d'un point de vue artistique : composition, couleurs, style, technique, Ã©motion transmise.",
            "technical": "Analyse les aspects techniques de cette image : qualitÃ©, Ã©clairage, perspective, mise au point, etc."
        }
        
        prompt = prompts.get(analysis_type, prompts["general"])
        
        # Appel Ã  l'API Vision avec le nouveau modÃ¨le
        response = client.chat.completions.create(
            model="gpt-4o",  # Nouveau modÃ¨le Vision d'OpenAI
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=500
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        st.error(f"âŒ Erreur lors de l'analyse de l'image: {str(e)}")
        return None

def extract_image_metadata(image):
    """Extrait les mÃ©tadonnÃ©es de base de l'image"""
    try:
        metadata = {
            "Format": image.format,
            "Mode": image.mode,
            "Taille": f"{image.size[0]} x {image.size[1]} pixels",
            "Nombre de canaux": len(image.getbands()) if hasattr(image, 'getbands') else "N/A"
        }
        
        # Essayer d'extraire des mÃ©tadonnÃ©es EXIF si disponibles
        if hasattr(image, '_getexif') and image._getexif():
            exif = image._getexif()
            if exif:
                metadata["EXIF disponible"] = "Oui"
        
        return metadata
    except Exception as e:
        return {"Erreur": f"Impossible d'extraire les mÃ©tadonnÃ©es: {str(e)}"}

# Section de saisie de la clÃ© API
st.subheader("ğŸ”‘ Configuration de l'API OpenAI")

col1, col2 = st.columns([3, 1])

with col1:
    api_key = st.text_input(
        "Entrez votre clÃ© API OpenAI:",
        type="password",
        placeholder="sk-proj-...",
        help="Votre clÃ© API OpenAI. Elle commence par 'sk-proj-' ou 'sk-'."
    )

with col2:
    st.markdown("### ğŸ’¡ Comment obtenir une clÃ© API ?")
    st.markdown("""
    1. Allez sur [platform.openai.com](https://platform.openai.com)
    2. Connectez-vous Ã  votre compte
    3. Allez dans "API Keys"
    4. CrÃ©ez une nouvelle clÃ©
    5. Copiez-la ici
    """)

# Initialisation du client OpenAI
client = None
if api_key:
    with st.spinner("ğŸ” Validation de la clÃ© API..."):
        client = initialize_openai_client(api_key)
    
    if client:
        st.success("âœ… ClÃ© API validÃ©e avec succÃ¨s !")
    else:
        st.warning("âš ï¸ ClÃ© API non validÃ©e. Veuillez vÃ©rifier votre clÃ©.")

# Interface utilisateur (seulement si la clÃ© API est valide)
if client:
    st.markdown("---")
    
    # Onglets pour diffÃ©rentes fonctionnalitÃ©s
    tab1, tab2, tab3 = st.tabs(["ğŸ–¼ï¸ Analyser une Image", "ğŸ“Š Analyse Comparative", "â„¹ï¸ Informations"])

    with tab1:
        st.header("Analyse d'Image avec Vision AI")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“¤ Upload d'Image")
            
            # Upload d'image
            uploaded_file = st.file_uploader(
                "Choisissez une image Ã  analyser",
                type=['png', 'jpg', 'jpeg', 'gif', 'bmp'],
                help="Formats supportÃ©s: PNG, JPG, JPEG, GIF, BMP"
            )
            
            if uploaded_file:
                image = Image.open(uploaded_file)
                st.image(image, caption="Image Ã  analyser", use_container_width=True)
                
                # MÃ©tadonnÃ©es de l'image
                with st.expander("ğŸ“‹ MÃ©tadonnÃ©es de l'image"):
                    metadata = extract_image_metadata(image)
                    for key, value in metadata.items():
                        st.text(f"{key}: {value}")
        
        with col2:
            st.subheader("ğŸ” Analyse")
            
            if uploaded_file:
                # Type d'analyse
                analysis_type = st.selectbox(
                    "Type d'analyse:",
                    ["general", "objects", "text", "detailed", "artistic", "technical"],
                    format_func=lambda x: {
                        "general": "ğŸ” Analyse gÃ©nÃ©rale",
                        "objects": "ğŸ¯ DÃ©tection d'objets",
                        "text": "ğŸ“ Reconnaissance de texte",
                        "detailed": "ğŸ“– Analyse dÃ©taillÃ©e",
                        "artistic": "ğŸ¨ Analyse artistique",
                        "technical": "âš™ï¸ Analyse technique"
                    }[x]
                )
                
                # Bouton d'analyse
                if st.button("ğŸš€ Analyser l'image", key="analyze", type="primary"):
                    with st.spinner("ğŸ”„ Analyse en cours..."):
                        analysis_result = vision_analyze_image(client, image, analysis_type)
                    
                    if analysis_result:
                        st.success("âœ… Analyse terminÃ©e !")
                        
                        # Affichage du rÃ©sultat
                        st.markdown("### ğŸ“‹ RÃ©sultat de l'analyse")
                        st.markdown(analysis_result)
                        
                        # Sauvegarder dans la session pour comparaison
                        if 'analyses' not in st.session_state:
                            st.session_state.analyses = []
                        
                        st.session_state.analyses.append({
                            'image': image.copy(),
                            'type': analysis_type,
                            'result': analysis_result,
                            'filename': uploaded_file.name
                        })
                        
                        st.info("ğŸ’¾ Analyse sauvegardÃ©e pour comparaison dans l'onglet 'Analyse Comparative'")
            else:
                st.info("ğŸ‘† Veuillez d'abord uploader une image")

    with tab2:
        st.header("ğŸ“Š Analyse Comparative")
        
        if 'analyses' in st.session_state and st.session_state.analyses:
            st.markdown(f"**{len(st.session_state.analyses)} analyse(s) sauvegardÃ©e(s)**")
            
            # Affichage des analyses prÃ©cÃ©dentes
            for i, analysis in enumerate(st.session_state.analyses):
                with st.expander(f"ğŸ“¸ {analysis['filename']} - {analysis['type']}"):
                    col1, col2 = st.columns([1, 2])
                    
                    with col1:
                        st.image(analysis['image'], caption=analysis['filename'], use_container_width=True)
                    
                    with col2:
                        st.markdown("**Type d'analyse:** " + analysis['type'])
                        st.markdown("**RÃ©sultat:**")
                        st.write(analysis['result'])
            
            # Bouton pour effacer l'historique
            if st.button("ğŸ—‘ï¸ Effacer l'historique"):
                st.session_state.analyses = []
                st.success("Historique effacÃ© !")
                st.rerun()
        else:
            st.info("Aucune analyse sauvegardÃ©e. Analysez des images dans l'onglet 'Analyser une Image' pour les voir ici.")

    with tab3:
        st.header("â„¹ï¸ Informations sur l'Analyse d'Images")
        
        st.markdown("""
        ### ğŸ¤– Ã€ propos de Vision AI
        
        Cette application utilise **GPT-4o** d'OpenAI pour analyser les images.
        GPT-4o est le modÃ¨le multimodal le plus rÃ©cent qui supporte l'analyse d'images.
        
        ### ğŸ¯ Types d'analyses disponibles
        
        **ğŸ” Analyse gÃ©nÃ©rale**
        - Description gÃ©nÃ©rale de l'image
        - Identification des Ã©lÃ©ments principaux
        - Contexte et ambiance
        
        **ğŸ¯ DÃ©tection d'objets**
        - Liste dÃ©taillÃ©e des objets identifiÃ©s
        - Position et caractÃ©ristiques des objets
        - Relations entre les Ã©lÃ©ments
        
        **ğŸ“ Reconnaissance de texte**
        - Extraction du texte visible
        - Transcription et contexte
        - Analyse du contenu textuel
        
        **ğŸ“– Analyse dÃ©taillÃ©e**
        - Analyse complÃ¨te et approfondie
        - Tous les Ã©lÃ©ments visuels
        - Description exhaustive
        
        **ğŸ¨ Analyse artistique**
        - Composition et style
        - Couleurs et technique
        - Ã‰motion et esthÃ©tique
        
        **âš™ï¸ Analyse technique**
        - QualitÃ© de l'image
        - Aspects techniques
        - Ã‰clairage et perspective
        
        ### ğŸ“‹ Formats supportÃ©s
        - PNG, JPG, JPEG
        - GIF, BMP
        - Taille maximale recommandÃ©e: 20MB
        
        ### ğŸ’¡ Conseils d'utilisation
        - Utilisez des images claires et bien Ã©clairÃ©es
        - Ã‰vitez les images trop petites ou floues
        - Essayez diffÃ©rents types d'analyse pour des rÃ©sultats variÃ©s
        - Sauvegardez vos analyses pour les comparer
        """)

else:
    # Message d'information si pas de clÃ© API
    st.info("ğŸ”‘ Veuillez entrer une clÃ© API OpenAI valide pour utiliser l'analyse d'images.")
    
    st.markdown("### ğŸ“‹ Instructions d'utilisation")
    st.markdown("""
    1. **Obtenez une clÃ© API** sur [platform.openai.com](https://platform.openai.com/api-keys)
    2. **Entrez votre clÃ©** dans le champ ci-dessus
    3. **Attendez la validation** (vÃ©rification automatique)
    4. **Uploadez une image** et choisissez le type d'analyse
    5. **Cliquez sur "Analyser l'image"** pour obtenir les rÃ©sultats
    
    âš ï¸ **Note de sÃ©curitÃ©:** Votre clÃ© API n'est pas stockÃ©e et reste privÃ©e Ã  votre session.
    """)

# Sidebar avec informations
with st.sidebar:
    st.markdown("### ğŸ‘ï¸ Vision AI")
    st.markdown("""
    **FonctionnalitÃ©s:**
    - ğŸ” Analyse gÃ©nÃ©rale d'images
    - ğŸ¯ DÃ©tection d'objets
    - ğŸ“ Reconnaissance de texte
    - ğŸ¨ Analyse artistique
    - âš™ï¸ Analyse technique
    - ğŸ“Š Comparaison d'analyses
    """)
    
    st.markdown("### ğŸ’¡ Avantages")
    st.markdown("""
    - Analyse prÃ©cise et dÃ©taillÃ©e
    - Multiples types d'analyses
    - Interface intuitive
    - Sauvegarde des rÃ©sultats
    - Pas de limite de format
    """)
    
    # Statut de la connexion API
    st.markdown("### ğŸ”Œ Statut de l'API")
    if client:
        st.success("ConnectÃ© âœ…")
    else:
        st.error("Non connectÃ© âŒ")

# Style CSS personnalisÃ©
st.markdown("""
<style>
    .stTextInput > div > div > input[type="password"] {
        font-family: monospace;
    }
    
    .analysis-result {
        background-color: #f0f2f6;
        padding: 15px;
        border-radius: 10px;
        border-left: 4px solid #4CAF50;
    }
</style>
""", unsafe_allow_html=True)
