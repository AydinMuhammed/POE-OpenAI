import streamlit as st
import openai
import json
import time
from datetime import datetime

#A L'aide de ChatGPT, cr√©ez un fichier de donn√©es d'entrainement au format JSONL contenant au moins 10 messages puis placez le dans un fichier data.jsonl Entrainez ensuite un mod√®le de chatbot sur un domaine de votre choix.

def create_sample_jsonl(filename="data.jsonl"):
    messages = [
        {"messages": [
            {"role": "system", "content": "Tu es un assistant expert en m√©t√©o."},
            {"role": "user", "content": "Quel temps fait-il √† Paris ?"},
            {"role": "assistant", "content": "Aujourd'hui √† Paris, il fait ensoleill√© avec 25¬∞C."}
        ]},
        {"messages": [
            {"role": "system", "content": "Tu es un assistant expert en m√©t√©o."},
            {"role": "user", "content": "Va-t-il pleuvoir demain √† Lyon ?"},
            {"role": "assistant", "content": "Demain √† Lyon, des averses sont pr√©vues dans l'apr√®s-midi."}
        ]},
        {"messages": [
            {"role": "system", "content": "Tu es un assistant expert en m√©t√©o."},
            {"role": "user", "content": "Quelle est la temp√©rature √† Marseille ?"},
            {"role": "assistant", "content": "Il fait actuellement 28¬∞C √† Marseille."}
        ]},
        {"messages": [
            {"role": "system", "content": "Tu es un assistant expert en m√©t√©o."},
            {"role": "user", "content": "Y a-t-il du vent √† Lille ?"},
            {"role": "assistant", "content": "Oui, il y a un vent mod√©r√© de 20 km/h √† Lille."}
        ]},
        {"messages": [
            {"role": "system", "content": "Tu es un assistant expert en m√©t√©o."},
            {"role": "user", "content": "Quel temps pour le week-end √† Bordeaux ?"},
            {"role": "assistant", "content": "Le week-end sera nuageux avec quelques √©claircies √† Bordeaux."}
        ]},
        {"messages": [
            {"role": "system", "content": "Tu es un assistant expert en m√©t√©o."},
            {"role": "user", "content": "Est-ce qu'il neige √† Grenoble ?"},
            {"role": "assistant", "content": "Non, il ne neige pas actuellement √† Grenoble."}
        ]},
        {"messages": [
            {"role": "system", "content": "Tu es un assistant expert en m√©t√©o."},
            {"role": "user", "content": "Peux-tu me donner la m√©t√©o √† Nice ?"},
            {"role": "assistant", "content": "√Ä Nice, il fait beau et chaud avec 30¬∞C."}
        ]},
        {"messages": [
            {"role": "system", "content": "Tu es un assistant expert en m√©t√©o."},
            {"role": "user", "content": "Quel est le taux d'humidit√© √† Nantes ?"},
            {"role": "assistant", "content": "Le taux d'humidit√© √† Nantes est de 60%."}
        ]},
        {"messages": [
            {"role": "system", "content": "Tu es un assistant expert en m√©t√©o."},
            {"role": "user", "content": "Va-t-il faire chaud √† Toulouse cette semaine ?"},
            {"role": "assistant", "content": "Oui, des temp√©ratures √©lev√©es sont attendues √† Toulouse cette semaine."}
        ]},
        {"messages": [
            {"role": "system", "content": "Tu es un assistant expert en m√©t√©o."},
            {"role": "user", "content": "Quel temps fait-il √† Strasbourg ?"},
            {"role": "assistant", "content": "√Ä Strasbourg, le ciel est partiellement couvert avec 22¬∞C."}
        ]}
    ]
    with open(filename, "w", encoding="utf-8") as f:
        for m in messages:
            f.write(json.dumps(m, ensure_ascii=False) + "\n")

#Cr√©ez une m√©thode openai_chat_finetune() qui prend en param√®tre le nom du fichier de donn√©es d'entrainement et retourne le nom du mod√®le entrain√©.
def openai_chat_finetune(training_file):
    # N√©cessite openai.api_key d√©j√† d√©fini
    with open(training_file, "rb") as f:
        file_response = openai.files.create(file=f, purpose="fine-tune")
    file_id = file_response.id
    fine_tune_response = openai.fine_tuning.jobs.create(
        training_file=file_id,
        model="gpt-3.5-turbo"
    )
    return fine_tune_response.id

def get_job_status(job_id):
    """R√©cup√®re le statut d'un job de fine-tuning"""
    try:
        job = openai.fine_tuning.jobs.retrieve(job_id)
        return job
    except Exception as e:
        st.error(f"Erreur lors de la r√©cup√©ration du statut: {str(e)}")
        return None

def get_job_events(job_id, limit=10):
    """R√©cup√®re les √©v√©nements d'un job de fine-tuning"""
    try:
        events = openai.fine_tuning.jobs.list_events(id=job_id, limit=limit)
        return events.data
    except Exception as e:
        st.error(f"Erreur lors de la r√©cup√©ration des √©v√©nements: {str(e)}")
        return []

def chat_with_model(model_id, messages, temperature=0.7):
    """Interagit avec un mod√®le fine-tun√©"""
    try:
        response = openai.chat.completions.create(
            model=model_id,
            messages=messages,
            temperature=temperature
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"Erreur lors de l'interaction avec le mod√®le: {str(e)}")
        return None

# Configuration de la page
st.set_page_config(
    page_title="Fine-tuning OpenAI",
    page_icon="ü§ñ",
    layout="wide"
)

st.title("ü§ñ Fine-tuning Chatbot OpenAI")
st.markdown("---")

# Section de saisie de la cl√© API
st.subheader("üîë Configuration de l'API OpenAI")

col1, col2 = st.columns([3, 1])

with col1:
    api_key = st.text_input(
        "Entrez votre cl√© API OpenAI:",
        type="password",
        placeholder="sk-...",
        help="Votre cl√© API OpenAI. Elle commence par 'sk-'."
    )

with col2:
    st.markdown("### üí° Comment obtenir une cl√© API ?")
    st.markdown("""
    1. Allez sur [platform.openai.com](https://platform.openai.com)
    2. Connectez-vous √† votre compte
    3. Allez dans "API Keys"
    4. Cr√©ez une nouvelle cl√©
    5. Copiez-la ici
    """)

if api_key:
    openai.api_key = api_key
    st.success("‚úÖ Cl√© API configur√©e")

    # Onglets pour diff√©rentes fonctionnalit√©s
    tab1, tab2, tab3, tab4 = st.tabs(["üìä Cr√©ation des donn√©es", "üöÄ Fine-tuning", "üîç Suivi des jobs", "üí¨ Tester le mod√®le"])

    with tab1:
        st.header("üìä Cr√©ation des donn√©es d'entra√Ænement")
        st.markdown("Cr√©ez un fichier JSONL contenant les exemples pour entra√Æner votre chatbot")
        
        # Options pour cr√©er des donn√©es
        data_option = st.radio(
            "Comment souhaitez-vous cr√©er vos donn√©es ?",
            ["Utiliser l'exemple pr√©d√©fini (m√©t√©o)", "Cr√©er un exemple personnalis√©"]
        )
        
        if data_option == "Utiliser l'exemple pr√©d√©fini (m√©t√©o)":
            if st.button("üì• G√©n√©rer le fichier data.jsonl", type="primary"):
                create_sample_jsonl()
                st.success("‚úÖ Fichier data.jsonl cr√©√© avec 10 exemples de m√©t√©o !")
                
                # Afficher un aper√ßu
                with open("data.jsonl", "r", encoding="utf-8") as f:
                    lines = f.readlines()[:3]  # Afficher les 3 premiers exemples
                
                st.markdown("### Aper√ßu des donn√©es")
                for i, line in enumerate(lines):
                    st.code(line, language="json")
                    if i < len(lines) - 1:
                        st.markdown("---")
                
                st.info(f"üìÅ Le fichier contient {len(open('data.jsonl', 'r', encoding='utf-8').readlines())} exemples au total.")
        else:
            st.markdown("### Cr√©ation d'exemples personnalis√©s")
            
            domain = st.text_input("Domaine d'expertise du chatbot", 
                                  placeholder="Ex: assistant culinaire, expert juridique, etc.")
            
            st.markdown("#### Exemple d'√©change (minimum 10 requis)")
            
            col1, col2 = st.columns(2)
            with col1:
                user_input = st.text_area("Question utilisateur", placeholder="Ex: Comment faire une p√¢te √† cr√™pes ?")
            with col2:
                assistant_output = st.text_area("R√©ponse assistant", placeholder="Ex: Pour faire une p√¢te √† cr√™pes, m√©langez 250g de farine...")
            
            if st.button("‚ûï Ajouter cet exemple"):
                if not domain or not user_input or not assistant_output:
                    st.warning("‚ö†Ô∏è Veuillez remplir tous les champs")
                else:
                    # Cr√©er ou charger le fichier JSONL
                    try:
                        examples = []
                        try:
                            with open("custom_data.jsonl", "r", encoding="utf-8") as f:
                                for line in f:
                                    examples.append(json.loads(line))
                        except FileNotFoundError:
                            pass  # Le fichier n'existe pas encore
                        
                        # Ajouter le nouvel exemple
                        examples.append({
                            "messages": [
                                {"role": "system", "content": f"Tu es un assistant expert en {domain}."},
                                {"role": "user", "content": user_input},
                                {"role": "assistant", "content": assistant_output}
                            ]
                        })
                        
                        # Sauvegarder
                        with open("custom_data.jsonl", "w", encoding="utf-8") as f:
                            for example in examples:
                                f.write(json.dumps(example, ensure_ascii=False) + "\n")
                        
                        st.success(f"‚úÖ Exemple ajout√©! ({len(examples)} exemples au total)")
                    except Exception as e:
                        st.error(f"Erreur: {str(e)}")
            
            # Afficher les exemples existants
            try:
                with open("custom_data.jsonl", "r", encoding="utf-8") as f:
                    examples = [json.loads(line) for line in f]
                
                if examples:
                    st.markdown(f"### Exemples enregistr√©s ({len(examples)})")
                    
                    if st.checkbox("Voir tous les exemples"):
                        for i, ex in enumerate(examples):
                            with st.expander(f"Exemple {i+1}"):
                                st.markdown(f"**Syst√®me:** {ex['messages'][0]['content']}")
                                st.markdown(f"**Utilisateur:** {ex['messages'][1]['content']}")
                                st.markdown(f"**Assistant:** {ex['messages'][2]['content']}")
            except FileNotFoundError:
                st.info("Aucun exemple personnalis√© enregistr√© pour le moment.")

    with tab2:
        st.header("üöÄ Lancement du Fine-tuning")
        st.markdown("Lancez l'entra√Ænement de votre mod√®le sur les donn√©es pr√©par√©es")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # S√©lection du fichier
            training_file = st.text_input("Nom du fichier d'entra√Ænement", 
                                        value="data.jsonl" if "data.jsonl" in [f.split("/")[-1] for f in ["data.jsonl"]] else "",
                                        placeholder="Ex: data.jsonl")
            
            # S√©lection du mod√®le de base
            base_model = st.selectbox(
                "Mod√®le de base",
                ["gpt-3.5-turbo", "gpt-3.5-turbo-1106", "gpt-3.5-turbo-0125", "davinci-002"],
                index=0
            )
            
            # Param√®tres avanc√©s
            with st.expander("‚öôÔ∏è Param√®tres avanc√©s"):
                epochs = st.slider("Nombre d'√©poques", min_value=1, max_value=10, value=3)
                batch_size = st.slider("Taille du batch", min_value=1, max_value=16, value=4)
                learning_rate_multiplier = st.slider("Multiplicateur du taux d'apprentissage", min_value=0.05, max_value=2.0, value=1.0, step=0.05)
        
        with col2:
            st.markdown("### üìã R√©sum√©")
            
            if training_file:
                try:
                    with open(training_file, "r", encoding="utf-8") as f:
                        example_count = len(f.readlines())
                    
                    st.info(f"üìÅ Fichier: {training_file}")
                    st.info(f"üìä Nombre d'exemples: {example_count}")
                    st.info(f"ü§ñ Mod√®le de base: {base_model}")
                    
                    if "epochs" in locals():
                        st.info(f"üîÑ √âpoques: {epochs}")
                except FileNotFoundError:
                    st.warning(f"‚ö†Ô∏è Le fichier {training_file} n'existe pas.")
            
            # Bouton de lancement
            if st.button("üöÄ Lancer le fine-tuning", type="primary"):
                if not training_file:
                    st.error("‚ö†Ô∏è Veuillez sp√©cifier un fichier d'entra√Ænement")
                else:
                    try:
                        with st.spinner("üì§ Upload du fichier en cours..."):
                            with open(training_file, "rb") as f:
                                file_response = openai.files.create(file=f, purpose="fine-tune")
                            file_id = file_response.id
                            
                        with st.spinner("üöÄ Lancement du job de fine-tuning..."):
                            fine_tune_response = openai.fine_tuning.jobs.create(
                                training_file=file_id,
                                model=base_model,
                                hyperparameters={
                                    "n_epochs": epochs if "epochs" in locals() else 3,
                                    "batch_size": batch_size if "batch_size" in locals() else 4,
                                    "learning_rate_multiplier": learning_rate_multiplier if "learning_rate_multiplier" in locals() else 1.0
                                }
                            )
                            
                            job_id = fine_tune_response.id
                            
                        st.success(f"‚úÖ Fine-tuning lanc√© avec succ√®s!")
                        st.markdown(f"### ID du job: `{job_id}`")
                        st.info("üëâ Utilisez l'onglet 'Suivi des jobs' pour v√©rifier le statut de votre fine-tuning")
                        
                        # Sauvegarde du job dans la session
                        if "jobs" not in st.session_state:
                            st.session_state.jobs = []
                        
                        st.session_state.jobs.append({
                            "id": job_id,
                            "file": training_file,
                            "model": base_model,
                            "started_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "status": "pending"
                        })
                    except Exception as e:
                        st.error(f"‚ùå Erreur: {str(e)}")

    with tab3:
        st.header("üîç Suivi des Jobs de Fine-tuning")
        st.markdown("V√©rifiez le statut et les d√©tails de vos jobs de fine-tuning")
        
        # Entr√©e manuelle d'un ID de job
        job_id_input = st.text_input("ID du job √† v√©rifier", 
                                    placeholder="ftjob-...",
                                    help="L'identifiant du job commence g√©n√©ralement par 'ftjob-'")
        
        # Afficher les jobs en session
        if "jobs" in st.session_state and st.session_state.jobs:
            st.markdown("### Jobs r√©cents")
            
            for job in st.session_state.jobs:
                with st.expander(f"Job: {job['id']} - {job['started_at']}"):
                    st.markdown(f"**Fichier:** {job['file']}")
                    st.markdown(f"**Mod√®le de base:** {job['model']}")
                    st.markdown(f"**D√©marr√© le:** {job['started_at']}")
                    
                    if st.button("üîÑ Rafra√Æchir le statut", key=f"refresh_{job['id']}"):
                        job_id_input = job['id']
        
        # V√©rification du statut
        if job_id_input:
            with st.spinner("üîç R√©cup√©ration des informations..."):
                job = get_job_status(job_id_input)
                
                if job:
                    # Affichage du statut
                    status_color = {
                        "pending": "üü°",
                        "running": "üîµ",
                        "succeeded": "üü¢",
                        "failed": "üî¥",
                        "cancelled": "‚ö™"
                    }.get(job.status, "‚ö™")
                    
                    st.markdown(f"### Statut: {status_color} {job.status.upper()}")
                    
                    # Informations d√©taill√©es
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("#### üìä Informations g√©n√©rales")
                        st.markdown(f"**ID:** `{job.id}`")
                        st.markdown(f"**Mod√®le de base:** {job.model}")
                        st.markdown(f"**Fichier d'entra√Ænement:** {job.training_file}")
                        st.markdown(f"**Cr√©√© le:** {job.created_at}")
                        
                    with col2:
                        st.markdown("#### ‚öôÔ∏è Param√®tres & Progression")
                        
                        if hasattr(job, 'hyperparameters'):
                            st.markdown(f"**√âpoques:** {job.hyperparameters.n_epochs}")
                        
                        if hasattr(job, 'result_files') and job.result_files:
                            st.markdown(f"**Fichiers r√©sultats:** {', '.join(job.result_files)}")
                        
                        if job.status == "succeeded" and hasattr(job, 'fine_tuned_model'):
                            st.markdown(f"**ü§ñ Mod√®le fine-tun√©:** `{job.fine_tuned_model}`")
                            # Stocker le nom du mod√®le dans la session pour l'onglet de test
                            if "fine_tuned_models" not in st.session_state:
                                st.session_state.fine_tuned_models = []
                            if job.fine_tuned_model not in st.session_state.fine_tuned_models:
                                st.session_state.fine_tuned_models.append(job.fine_tuned_model)
                    
                    # √âv√©nements du job
                    st.markdown("#### üìù Journal des √©v√©nements")
                    events = get_job_events(job_id_input)
                    
                    if events:
                        for event in events:
                            event_time = datetime.fromtimestamp(event.created_at).strftime("%Y-%m-%d %H:%M:%S")
                            st.markdown(f"**[{event_time}]** {event.message}")
                    else:
                        st.info("Aucun √©v√©nement disponible pour le moment.")

    with tab4:
        st.header("üí¨ Tester votre mod√®le Fine-tun√©")
        st.markdown("Interagissez avec votre mod√®le fine-tun√© pour √©valuer ses performances")
        
        # Section pour r√©cup√©rer l'ID du mod√®le √† partir de l'ID du job
        st.markdown("### üîç R√©cup√©rer l'ID du mod√®le")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### Option 1: √Ä partir de l'ID du job")
            job_id_for_model = st.text_input(
                "ID du job termin√©",
                placeholder="ftjob-...",
                help="L'ID du job de fine-tuning qui a r√©ussi"
            )
            
            if st.button("üîÑ R√©cup√©rer l'ID du mod√®le"):
                if job_id_for_model:
                    with st.spinner("üîç R√©cup√©ration de l'ID du mod√®le..."):
                        job = get_job_status(job_id_for_model)
                        if job and job.status == "succeeded" and hasattr(job, 'fine_tuned_model'):
                            model_id = job.fine_tuned_model
                            st.success(f"‚úÖ Mod√®le trouv√©: `{model_id}`")
                            # Stocker dans la session
                            if "retrieved_model_id" not in st.session_state:
                                st.session_state.retrieved_model_id = model_id
                            else:
                                st.session_state.retrieved_model_id = model_id
                        else:
                            st.error("‚ùå Job non trouv√© ou non termin√© avec succ√®s")
        
        with col2:
            st.markdown("#### Option 2: Saisie directe")
            # S√©lection du mod√®le
            models = []
            if "fine_tuned_models" in st.session_state and st.session_state.fine_tuned_models:
                models = st.session_state.fine_tuned_models
            
            # Utiliser l'ID r√©cup√©r√© s'il existe
            default_model = ""
            if "retrieved_model_id" in st.session_state:
                default_model = st.session_state.retrieved_model_id
            elif models:
                default_model = models[0]
            
            model_input = st.text_input(
                "ID du mod√®le fine-tun√©",
                placeholder="ft:gpt-3.5-turbo:...",
                value=default_model,
                help="L'identifiant du mod√®le commence par 'ft:' (pas 'ftjob-')"
            )
            
            if model_input:
                if model_input.startswith("ftjob-"):
                    st.error("‚ö†Ô∏è Ceci est un ID de job, pas de mod√®le. Utilisez l'option 1 pour r√©cup√©rer l'ID du mod√®le.")
                elif model_input.startswith("ft:"):
                    st.success("‚úÖ Format d'ID de mod√®le correct")
                else:
                    st.warning("‚ö†Ô∏è L'ID du mod√®le devrait commencer par 'ft:'")
        
        st.markdown("---")
        
        # Interface de chat
        st.markdown("### üí¨ Interface de Chat")
        
        # Initialiser l'historique de chat s'il n'existe pas
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # Afficher les messages existants
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # Zone de saisie utilisateur
        if prompt := st.chat_input("Posez votre question..."):
            if not model_input:
                st.error("‚ö†Ô∏è Veuillez sp√©cifier un ID de mod√®le fine-tun√©")
            else:
                # Ajouter le message utilisateur √† l'historique
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # Afficher le message utilisateur
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # Pr√©parer les messages pour l'API
                messages_for_api = [
                    {"role": "system", "content": "Tu es un assistant expert dans le domaine pour lequel tu as √©t√© fine-tun√©."}
                ]
                messages_for_api.extend(st.session_state.messages)
                
                # G√©n√©rer la r√©ponse
                with st.chat_message("assistant"):
                    with st.spinner("G√©n√©ration en cours..."):
                        response = chat_with_model(model_input, messages_for_api)
                        
                        if response:
                            st.markdown(response)
                            # Ajouter la r√©ponse √† l'historique
                            st.session_state.messages.append({"role": "assistant", "content": response})
        
        # Options de param√©trage
        with st.expander("‚öôÔ∏è Param√®tres de g√©n√©ration"):
            temperature = st.slider("Temp√©rature", min_value=0.0, max_value=2.0, value=0.7, step=0.1,
                                   help="Plus la valeur est √©lev√©e, plus les r√©ponses sont cr√©atives mais potentiellement moins pr√©cises.")
            
            if st.button("üßπ Effacer la conversation"):
                st.session_state.messages = []
                st.experimental_rerun()
else:
    st.info("üîë Veuillez entrer une cl√© API OpenAI valide pour utiliser le fine-tuning.")

# Sidebar avec informations
with st.sidebar:
    st.markdown("### ü§ñ Fine-tuning OpenAI")
    st.markdown("""
    **√âtapes du Fine-tuning:**
    1. üìä Pr√©paration des donn√©es (JSONL)
    2. üöÄ Lancement de l'entra√Ænement
    3. üîç Suivi du job de fine-tuning
    4. üí¨ Test du mod√®le personnalis√©
    """)
    
    st.markdown("### üìö Ressources")
    st.markdown("""
    - [Documentation Fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)
    - [Format JSONL](https://jsonlines.org/)
    - [Bonnes pratiques](https://platform.openai.com/docs/guides/fine-tuning/best-practices)
    """)
    
    # Statut de la connexion API
    st.markdown("### üîå Statut de l'API")
    if api_key:
        st.success("Connect√© ‚úÖ")
    else:
        st.error("Non connect√© ‚ùå")

# Style CSS personnalis√©
st.markdown("""
<style>
    .stTextInput > div > div > input[type="password"] {
        font-family: monospace;
    }
</style>
""", unsafe_allow_html=True)
